---
title: "ColorFool: Semantic Adversarial Colorization"
collection: publications
permalink: /publication/2019_11_25_ColorFool
excerpt: '[<b>Paper</b>](https://arxiv.org/pdf/1911.10891.pdf), ,
[<b>Code</b>](https://github.com/AliShahin/ColorFool).'
date: 2020-06-14
venue: 'IEEE Conference on Computer Vision and Pattern Recognition <b> (CVPR)</b>'
citation: 'Ali Shahin Shamsabadi, Ricardo Sanchez-Matilla, Andrea Cavallaro. &quot;ColorFool: Semantic Adversarial Colorization.&quot; <i> IEEE Conference on Computer Vision and Pattern Recognition (CVPR), </i> May 14-19, 2020, Seattle, Washington, US.' 
---
Adversarial attacks that generate small Lp-norm per- turbations to mislead classifiers have limited success in black-box settings and with unseen classifiers. These at- tacks are also not robust to defenses that use denoising fil- ters and to adversarial training procedures. Instead, ad- versarial attacks that generate unrestricted perturbations are more robust to defenses, are generally more success- ful in black-box settings and are more transferable to un- seen classifiers. However, unrestricted perturbations may be noticeable to humans. In this paper, we propose a content-based black-box adversarial attack that generates unrestricted perturbations by exploiting image semantics to selectively modify colors within chosen ranges that are perceived as natural by humans. We show that the pro- posed approach, ColorFool, outperforms in terms of suc- cess rate, robustness to defense frameworks and transfer- ability, five state-of-the-art adversarial attacks on two dif- ferent tasks, scene and object classification, when attack- ing three state-of-the-art deep neural networks using three standard datasets. The source code is available at https://github.com/smartcameras/ColorFool.
[Download paper here](https://arxiv.org/pdf/1911.10891.pdf)

